# PAN

2018 | [paper](https://arxiv.org/pdf/1803.01534v4.pdf) | _Path Aggregation Network for Instance Segmentation_

The way that information propagates in neural networks is of great importance. In this paper, authors proposed Path Aggregation Network (PANet) aiming at boosting information flow in proposal-based instance segmentation framework. Specifically, they enhanced the entire feature hierarchy with accurate localization signals in lower layers by bottom-up path augmentation, which shortens the information path between lower layers and topmost feature. The adaptive feature pooling was presented, which links feature grid and all feature levels to make useful information in each feature level propagate directly to following proposal subnetworks. A complementary branch capturing different views for each proposal is created to further improve mask prediction.

During the research authors notes that information propagation in SoTA Mask R-CNN can be further improved. Specifically, features in low levels are helpful for large instance identification. But there is a long path from low-level structure to topmost features, increasing difficulty to access accurate localization information. Further, each proposal is predicted based on feature grids pooled from one feature level, which is assigned heuristically. This process can be updated since information discarded in other levels may be helpful for final prediction. Finally, mask prediction is made on a single view, losing the chance to gather more diverse information.

<p align="center">
  <img src="https://github.com/thawro/yolo-pytorch/assets/50373360/affbff14-7d90-4515-812d-1c6965e9fd82" alt="PANet" height="350"/>
</p>

Inspired by these principles and observations, wthey proposed PANet, illustrated above, for instance segmentation with followint properties:

* To shorten information path and enhance feature pyramid with accurate localization signals existing in low-levels, bottom-up path augmentation is created. In fact, features in low-layers were utilized in the earlier works, but propagating low-level features to enhance entire feature hierarchy for instance recognition was not explored
* Second, to recover broken information path between each proposal and all feature levels, they develop adaptive feature pooling. It is a simple component to aggregate features from all feature levels for each proposal, avoiding arbitrarily assigned results. With this operation, cleaner paths are created.
* Finally, to capture different views of each proposal, they augmented mask prediction with tiny fully-connected (fc) layers, which possess complementary properties to FCN originally used by Mask R-CNN. By fusing predictions from these two views, information diversity increases and masks with better quality are produced. 

The first two components are shared by both object detection and instance segmentation, leading to much enhanced performance of both tasks

## Framework

The framework is illustrated in figure above. Path augmentation and aggregation is conducted for improving performance. A bottom-up path is augmented to make low-layer information easier to propagate. adaptive feature pooling is designed to allow each proposal to access information from all levels for prediction. A complementary path is added to the mask-prediction branch. This new structure leads to decent performance. Similar to FPN, the improvement is independent of the CNN structure.

### Bottom-up Path Augmentation

**Motivation** - The insightful point from earlier works is that neurons in high layers strongly respond to entire objects while other neurons are more likely to be activated by local texture and patterns manifests the necessity of augmenting a top-down path to propagate semantically strong features and enhance all features with reasonable classification capability in FPN. PANet framework further enhances the localization capability of the entire feature hierarchy by propagating strong responses of low-level patterns based on the fact that high response to edges or instance parts is a strong indicator to accurately localize instances. PANet path is built with clean lateral connections from the low level to top ones. Therefore, there is a “shortcut” (dashed green line in figure above), which consists of less than 10 layers, across these levels. In comparison, the CNN trunk in FPN gives a long path (dashed red line) passing through even 100+ layers from low layers to the topmost one. 

**Augmented Bottom-up Structure** - PANet framework first accomplishes bottom-up path augmentation. Authors followed FPN to define that layers producing feature maps with the same spatial size are in the same network stage. Each feature level corresponds to one stage. ResNet is used as the basic structure and ${P_2, P_3, P_4, P_5}$ denote feature levels generated by FPN. The augmented path starts from the lowest level $P_2$ and gradually approaches $P_5$ as shown in figure above. From $P_2$ to $P_5$, the spatial size is gradually down-sampled with factor 2. Authors use ${N_2, N_3, N_4, N_5}$ to denote newly generated feature maps corresponding to ${P_2, P_3, P_4, P_5}$. Note that $N_2$ is simply $P_2$, without any processing. The building block of PFANet is shown below:

<p align="center">
  <img src="https://github.com/thawro/yolo-pytorch/assets/50373360/ec075dfe-c9db-4999-8d1a-80c6e1287281" alt="PANet_block" height="350"/>
</p>

Each building block takes a higher resolution feature map $N_i$ and a coarser map $P_{i+1}$ through lateral connection and generates the new feature map $N_{i+1}$. Each feature map $N_i$ first goes through a $3 × 3$ convolutional layer with stride 2 to reduce the spatial size. Then each element of feature map $P_{i+1}$ and the down-sampled map are added through lateral connection. The fused feature map is then processed by another $3 × 3$ convolutional layer to generate $N_{i+1}$ for following sub-networks. This is an iterative process and terminates after approaching $P_5$. In these building blocks, we consistently use channel 256 of feature maps. All convolutional layers are followed by a ReLU. The feature grid for each proposal is then pooled from new feature maps, i.e., ${N_2, N_3, N_4, N_5}$.

Comparison of FPN and PAN:
<p align="center">
  <img src="https://github.com/thawro/yolo-pytorch/assets/50373360/2b674b4f-a54d-44b1-8cf9-ef1b6ec61da3" alt="PAN_vs_FPN" height="350"/>
</p>

### Adaptive Feature Pooling

Adaptive Feature Pooling is a component of the PANet framework designed for instance segmentation. It involves pooling features from all levels of the feature hierarchy for each proposal and fusing them for prediction. It was added to PANet to address the limitations of traditional methods where proposals were assigned to different feature levels based on their size, which could lead to suboptimal results. By pooling features from all levels for each proposal, Adaptive Feature Pooling allows the network to access context information from multiple levels, leading to more accurate predictions. This approach ensures that both small proposals can access high-level features with rich context information, and large proposals can access low-level features with fine details and high localization accuracy. Ultimately, Adaptive Feature Pooling enhances the network's ability to make accurate predictions for instance segmentation tasks

### Fully Connected Fusion

Fully-connected Fusion is a technique used in the PANet framework to improve mask prediction in instance segmentation. It involves adding a fully-connected branch to the mask prediction branch, which fuses predictions from both fully-connected layers and convolutional layers. It was added because fully-connected layers have different properties compared to convolutional layers. Fully-connected layers are location-sensitive and can adapt to different spatial locations, making them effective in predicting masks for instances. By fusing predictions from both fully-connected and convolutional layers, PANet aims to leverage the strengths of each type of layer to enhance mask prediction accuracy and differentiate between instances more effectively. The figure below shows how fully connected fusion works.

<p align="center">
  <img src="https://github.com/thawro/yolo-pytorch/assets/50373360/9fa8c975-9f08-46c6-92c9-1c9aaa60d1d9" alt="PANet_fc_fusion" height="350"/>
</p>

> **_NOTE:_** Most of the new YOLO approaches make use of the **Bottom-up Path Augmentation** idea from PANet. It is improved to BiFPN in future work.
