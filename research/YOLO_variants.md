# YOLO variants

| Year | Done | Approach | Link | Title |
| :--- | :---: | :--------------- | :---- | :---- |
| 2016 | âœ… | [YOLOv1](variants/YOLOv1.md) | [paper](https://arxiv.org/pdf/1506.02640.pdf) | You Only Look Once: Unified, Real-Time Object Detection |
| 2016 | âœ… | [YOLOv2](variants/YOLOv2.md), YOLO9000 | [paper](https://arxiv.org/pdf/1612.08242.pdf) | YOLO9000: Better, Faster, Stronger |
| 2018 | âœ… | [YOLOv3](variants/YOLOv3.md) | [paper](https://arxiv.org/pdf/1804.02767.pdf), [video](https://www.youtube.com/watch?v=Grir6TZbc1M), [blog](https://blog.paperspace.com/how-to-implement-a-yolo-object-detector-in-pytorch/), [code](https://github.com/ultralytics/yolov3) | YOLOv3: An Incremental Improvement |
| 2019 | âœ… | [Gaussian YOLO](variants/Gaussian-YOLO.md) | [paper](https://arxiv.org/pdf/1904.04620) | Gaussian YOLOv3: An Accurate and Fast Object Detector Using Localization Uncertainty for Autonomous Driving |
| 2020 | âœ… | [PP-YOLO](variants/PP-YOLO.md) | [paper](https://arxiv.org/pdf/2007.12099) | PP-YOLO: An Effective and Efficient Implementation of Object Detector |
| 2020 | âœ… | [YOLOv4](variants/YOLOv4.md) | [paper](https://arxiv.org/pdf/2004.10934.pdf) , [blog](https://alexeyab84.medium.com/yolov4-the-most-accurate-real-time-neural-network-on-ms-coco-dataset-73adfd3602fe), [code_1](https://github.com/WongKinYiu/PyTorch_YOLOv4), [code_2](https://github.com/Tianxiaomo/pytorch-YOLOv4) | YOLOv4: Optimal Speed and Accuracy of Object Detection |
| 2020 | âœ… | [YOLOv5](variants/YOLOv5.md) | [code](https://github.com/ultralytics/yolov5) | YOLOv5 |
| 2021 | âœ… | [Scaled-YOLOv4](variants/YOLOv4-Scaled.md) | [paper](https://arxiv.org/pdf/2011.08036.pdf) , [blog](https://alexeyab84.medium.com/scaled-yolo-v4-is-the-best-neural-network-for-object-detection-on-ms-coco-dataset-39dfa22fa982), [code](https://github.com/WongKinYiu/ScaledYOLOv4) | Scaled-YOLOv4: Scaling Cross Stage Partial Network |
| 2021 | ðŸ”³ | [YOLOR](variants/YOLOR.md) | [paper](https://arxiv.org/pdf/2105.04206), [code](https://github.com/WongKinYiu/yolor) | You Only Learn One Representation: Unified Network for Multiple Tasks |
| 2021 | ðŸ”³ | [YOLOX](variants/YOLOX.md) | [paper](https://arxiv.org/pdf/2107.08430.pdf) | YOLOX: Exceeding YOLO Series in 2021 |
| 2021 | ðŸ”³ | [PP-YOLOv2](variants/PP-YOLOv2.md) | [paper](https://arxiv.org/pdf/2104.10419) | PP-YOLOv2: A Practical Object Detector |
| 2022 | ðŸ”³ | [PP-YOLOE](variants/PP-YOLOE.md) | [paper](http://arxiv.org/pdf/2203.16250v3) | PP-YOLOE: An evolved version of YOLO |
| 2022 | ðŸ”³ | [RTMDet](variants/RTMDet.md) | [paper](http://arxiv.org/pdf/2212.07784v2) | RTMDet: An Empirical Study of Designing Real-Time Object Detectors |
| 2022 | ðŸ”³ | [YOLOv7](variants/YOLOv7.md) | [paper](https://arxiv.org/pdf/2207.02696.pdf), [code](https://github.com/WongKinYiu/yolov7) | YOLOv7: Trainable bag-of-freebies sets new state-of-the-art for real-time object detectors |
| 2022 | ðŸ”³ | [YOLOv6](variants/YOLOv6.md) | [paper](https://arxiv.org/pdf/2209.02976), [code](https://github.com/meituan/YOLOv6) | YOLOv6: A Single-Stage Object Detection Framework for Industrial Applications |
| 2022 | ðŸ”³ | [PP-YOLOE-R](variants/PP-YOLOE-R.md) | [paper](https://arxiv.org/pdf/2211.02386) | PP-YOLOE-R: An Efficient Anchor-Free Rotated Object Detector |
| 2023 | ðŸ”³ | [DAMA-YOLO](variants/DAMA-YOLO.md) | [paper](http://arxiv.org/pdf/2211.15444v4) | DAMO-YOLO : A Report on Real-Time Object Detection Design |
| 2023 | ðŸ”³ | [YOLOv6.3](variants/YOLOv6.3.md) | [paper](https://arxiv.org/pdf/2301.05586.pdf) | YOLOv6 v3.0: A Full-Scale Reloading |
| 2023 | ðŸ”³ | [Dy-YOLOv7](variants/Dy-YOLOv7.md) | [paper](https://arxiv.org/pdf/2304.05552) | DynamicDet: A Unified Dynamic Architecture for Object Detection |
| 2023 | ðŸ”³ | [YOLO Review](variants/Review.md) | [paper](https://arxiv.org/pdf/2304.00501.pdf) | A comprehensive review of YOLO: from YOLOv1 and beyond |
| 2023 | ðŸ”³ | [YOLOv8](variants/YOLOv8.md) | [code](https://github.com/ultralytics/ultralytics) | YOLOv8 |
| 2024 | ðŸ”³ | [YOLOv9](variants/YOLOv9.md) | [paper](https://arxiv.org/pdf/2402.13616), [code](https://github.com/WongKinYiu/yolov9) | YOLOv9: Learning What You Want to Learn Using Programmable Gradient Information |
